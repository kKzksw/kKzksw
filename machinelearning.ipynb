{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:01.128398Z",
     "start_time": "2024-12-03T08:29:59.358786Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold,GridSearchCV,cross_val_score\n",
    "#import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "#from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018a5301-96ae-41da-a3bd-91d55e8877e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.getrecursionlimit())\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fdf0881-8c05-49ad-9cb5-ec9317e94da7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from catboost) (1.11.4)\n",
      "Requirement already satisfied: plotly in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from matplotlib->catboost) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from matplotlib->catboost) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from matplotlib->catboost) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from plotly->catboost) (8.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install  catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8496f0bc36715303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:01.134833Z",
     "start_time": "2024-12-03T08:30:01.129399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/daisydu/Desktop'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_repo = os.path.dirname(os.getcwd())\n",
    "path_to_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e23b62de3edb8e5",
   "metadata": {},
   "source": [
    "### $\\bullet$ Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4876f791b1b145a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:35:50.356284Z",
     "start_time": "2024-12-03T08:35:50.352687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/daisydu/Desktop/machine learning/dataset/\n"
     ]
    }
   ],
   "source": [
    "path_to_dataset = os.path.join(path_to_repo, \"machine learning\", 'dataset', '')\n",
    "print(path_to_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "238305c2adfabd17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:36:10.328348Z",
     "start_time": "2024-12-03T08:36:10.104145Z"
    }
   },
   "outputs": [],
   "source": [
    "import chardet\n",
    "import pandas as pd\n",
    "\n",
    "with open(path_to_dataset+'creditcard_processed.csv', 'rb') as f:\n",
    "    enc = chardet.detect(f.read())\n",
    "    \n",
    "df = pd.read_csv(path_to_dataset+'creditcard_processed.csv', encoding = enc['encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d3543f375dfe989",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:36:12.997407Z",
     "start_time": "2024-12-03T08:36:12.988311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 96696 entries, 0 to 96695\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   month                     96696 non-null  int64  \n",
      " 1   age                       96696 non-null  int64  \n",
      " 2   occupation                96696 non-null  int64  \n",
      " 3   annual_income             96696 non-null  float64\n",
      " 4   monthly_inhand_salary     96696 non-null  float64\n",
      " 5   credit_history_age        96696 non-null  int64  \n",
      " 6   total_emi_per_month       96696 non-null  float64\n",
      " 7   num_bank_accounts         96696 non-null  int64  \n",
      " 8   num_credit_card           96696 non-null  int64  \n",
      " 9   interest_rate             96696 non-null  int64  \n",
      " 10  num_of_loan               96696 non-null  int64  \n",
      " 11  delay_from_due_date       96696 non-null  int64  \n",
      " 12  num_of_delayed_payment    96696 non-null  int64  \n",
      " 13  changed_credit_limit      96696 non-null  float64\n",
      " 14  num_credit_inquiries      96696 non-null  int64  \n",
      " 15  credit_mix                96696 non-null  int64  \n",
      " 16  outstanding_debt          96696 non-null  float64\n",
      " 17  credit_utilization_ratio  96696 non-null  float64\n",
      " 18  payment_of_min_amount     96696 non-null  int64  \n",
      " 19  amount_invested_monthly   96696 non-null  float64\n",
      " 20  payment_behaviour         96696 non-null  int64  \n",
      " 21  monthly_balance           96696 non-null  float64\n",
      " 22  credit_score              96696 non-null  int64  \n",
      "dtypes: float64(8), int64(15)\n",
      "memory usage: 17.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30a1f4256e7954",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:36:13.144056Z",
     "start_time": "2024-12-03T08:36:13.140545Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_vals(df, n): \n",
    "    return df[:n].copy(), df[n:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f46b47392cbead87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:36:13.322109Z",
     "start_time": "2024-12-03T08:36:13.311590Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df['credit_score']\n",
    "df = df.drop(['credit_score'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f275d831b29a2448",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:36:13.493429Z",
     "start_time": "2024-12-03T08:36:13.476414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of small training data points: X = (20000, 22), y = (20000,)\n",
      "Number of full training data points: X = (84696, 22), y = (84696,)\n",
      "Number of validation data points: X = (12000, 22), y = (12000,)\n"
     ]
    }
   ],
   "source": [
    "n_total = len(df)\n",
    "n_valid = 12000  \n",
    "n_train = n_total - n_valid\n",
    "n_small = 20000\n",
    "\n",
    "X_train, X_valid = split_vals(df, n_train)\n",
    "y_train, y_valid = split_vals(y, n_train)\n",
    "\n",
    "X_small, _ = split_vals(df, n_small)\n",
    "y_small, _ = split_vals(y, n_small)\n",
    "\n",
    "print('Number of small training data points: X = {}, y = {}'.format(X_small.shape, y_small.shape))\n",
    "print('Number of full training data points: X = {}, y = {}'.format(X_train.shape, y_train.shape))\n",
    "print('Number of validation data points: X = {}, y = {}'.format(X_valid.shape, y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "521020b5df7daa0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:36:14.385121Z",
     "start_time": "2024-12-03T08:36:14.379608Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def print_score(m, X_train, y_train, X_valid, y_valid):\n",
    "    # train set accuracy\n",
    "    train_pred = m.predict(X_train)\n",
    "    print('Accuracy on train set: {:.4f}'.format(accuracy_score(y_train, train_pred)))\n",
    "    # valid set accuracy\n",
    "    valid_pred = m.predict(X_valid)\n",
    "    print('Accuracy on valid set: {:.4f}'.format(accuracy_score(y_valid, valid_pred)))\n",
    "    # train & valid set classification report\n",
    "    print('Classification Report on train set:\\n', classification_report(y_train, train_pred))\n",
    "    print('Classification Report on valid set:\\n', classification_report(y_valid, valid_pred))\n",
    "    # train & valiid set confusion matrix\n",
    "    print('Confusion Matrix on train set:\\n', confusion_matrix(y_train, train_pred))\n",
    "    print('Confusion Matrix on valid set:\\n', confusion_matrix(y_valid, valid_pred))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42a79ca50125e32d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:33:31.328359Z",
     "start_time": "2024-12-03T08:33:31.314263Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class CatBoostRegressor in module catboost.core:\n",
      "\n",
      "class CatBoostRegressor(CatBoost)\n",
      " |  CatBoostRegressor(iterations=None, learning_rate=None, depth=None, l2_leaf_reg=None, model_size_reg=None, rsm=None, loss_function='RMSE', border_count=None, feature_border_type=None, per_float_feature_quantization=None, input_borders=None, output_borders=None, fold_permutation_block=None, od_pval=None, od_wait=None, od_type=None, nan_mode=None, counter_calc_method=None, leaf_estimation_iterations=None, leaf_estimation_method=None, thread_count=None, random_seed=None, use_best_model=None, best_model_min_trees=None, verbose=None, silent=None, logging_level=None, metric_period=None, ctr_leaf_count_limit=None, store_all_simple_ctr=None, max_ctr_complexity=None, has_time=None, allow_const_label=None, target_border=None, one_hot_max_size=None, random_strength=None, random_score_type=None, name=None, ignored_features=None, train_dir=None, custom_metric=None, eval_metric=None, bagging_temperature=None, save_snapshot=None, snapshot_file=None, snapshot_interval=None, fold_len_multiplier=None, used_ram_limit=None, gpu_ram_part=None, pinned_memory_size=None, allow_writing_files=None, final_ctr_computation_mode=None, approx_on_full_history=None, boosting_type=None, simple_ctr=None, combinations_ctr=None, per_feature_ctr=None, ctr_description=None, ctr_target_border_count=None, task_type=None, device_config=None, devices=None, bootstrap_type=None, subsample=None, mvs_reg=None, sampling_frequency=None, sampling_unit=None, dev_score_calc_obj_block_size=None, dev_efb_max_buckets=None, sparse_features_conflict_fraction=None, max_depth=None, n_estimators=None, num_boost_round=None, num_trees=None, colsample_bylevel=None, random_state=None, reg_lambda=None, objective=None, eta=None, max_bin=None, gpu_cat_features_storage=None, data_partition=None, metadata=None, early_stopping_rounds=None, cat_features=None, grow_policy=None, min_data_in_leaf=None, min_child_samples=None, max_leaves=None, num_leaves=None, score_function=None, leaf_estimation_backtracking=None, ctr_history_unit=None, monotone_constraints=None, feature_weights=None, penalties_coefficient=None, first_feature_use_penalties=None, per_object_feature_penalties=None, model_shrink_rate=None, model_shrink_mode=None, langevin=None, diffusion_temperature=None, posterior_sampling=None, boost_from_average=None, text_features=None, tokenizers=None, dictionaries=None, feature_calcers=None, text_processing=None, embedding_features=None, eval_fraction=None, fixed_binary_splits=None)\n",
      " |  \n",
      " |  Implementation of the scikit-learn API for CatBoost regression.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  Like in CatBoostClassifier, except loss_function, classes_count, class_names and class_weights\n",
      " |  \n",
      " |  loss_function : string, [default='RMSE']\n",
      " |      'RMSE'\n",
      " |      'MAE'\n",
      " |      'Quantile:alpha=value'\n",
      " |      'LogLinQuantile:alpha=value'\n",
      " |      'Poisson'\n",
      " |      'MAPE'\n",
      " |      'Lq:q=value'\n",
      " |      'SurvivalAft:dist=value;scale=value'\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CatBoostRegressor\n",
      " |      CatBoost\n",
      " |      _CatBoostBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, iterations=None, learning_rate=None, depth=None, l2_leaf_reg=None, model_size_reg=None, rsm=None, loss_function='RMSE', border_count=None, feature_border_type=None, per_float_feature_quantization=None, input_borders=None, output_borders=None, fold_permutation_block=None, od_pval=None, od_wait=None, od_type=None, nan_mode=None, counter_calc_method=None, leaf_estimation_iterations=None, leaf_estimation_method=None, thread_count=None, random_seed=None, use_best_model=None, best_model_min_trees=None, verbose=None, silent=None, logging_level=None, metric_period=None, ctr_leaf_count_limit=None, store_all_simple_ctr=None, max_ctr_complexity=None, has_time=None, allow_const_label=None, target_border=None, one_hot_max_size=None, random_strength=None, random_score_type=None, name=None, ignored_features=None, train_dir=None, custom_metric=None, eval_metric=None, bagging_temperature=None, save_snapshot=None, snapshot_file=None, snapshot_interval=None, fold_len_multiplier=None, used_ram_limit=None, gpu_ram_part=None, pinned_memory_size=None, allow_writing_files=None, final_ctr_computation_mode=None, approx_on_full_history=None, boosting_type=None, simple_ctr=None, combinations_ctr=None, per_feature_ctr=None, ctr_description=None, ctr_target_border_count=None, task_type=None, device_config=None, devices=None, bootstrap_type=None, subsample=None, mvs_reg=None, sampling_frequency=None, sampling_unit=None, dev_score_calc_obj_block_size=None, dev_efb_max_buckets=None, sparse_features_conflict_fraction=None, max_depth=None, n_estimators=None, num_boost_round=None, num_trees=None, colsample_bylevel=None, random_state=None, reg_lambda=None, objective=None, eta=None, max_bin=None, gpu_cat_features_storage=None, data_partition=None, metadata=None, early_stopping_rounds=None, cat_features=None, grow_policy=None, min_data_in_leaf=None, min_child_samples=None, max_leaves=None, num_leaves=None, score_function=None, leaf_estimation_backtracking=None, ctr_history_unit=None, monotone_constraints=None, feature_weights=None, penalties_coefficient=None, first_feature_use_penalties=None, per_object_feature_penalties=None, model_shrink_rate=None, model_shrink_mode=None, langevin=None, diffusion_temperature=None, posterior_sampling=None, boost_from_average=None, text_features=None, tokenizers=None, dictionaries=None, feature_calcers=None, text_processing=None, embedding_features=None, eval_fraction=None, fixed_binary_splits=None)\n",
      " |      Initialize the CatBoost.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : dict\n",
      " |          Parameters for CatBoost.\n",
      " |          If  None, all params are set to their defaults.\n",
      " |          If  dict, overriding parameters present in dict.\n",
      " |  \n",
      " |  fit(self, X, y=None, cat_features=None, text_features=None, embedding_features=None, graph=None, sample_weight=None, baseline=None, use_best_model=None, eval_set=None, verbose=None, logging_level=None, plot=False, plot_file=None, column_description=None, verbose_eval=None, metric_period=None, silent=None, early_stopping_rounds=None, save_snapshot=None, snapshot_file=None, snapshot_interval=None, init_model=None, callbacks=None, log_cout=None, log_cerr=None)\n",
      " |      Fit the CatBoost model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : catboost.Pool or list or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |          If not catboost.Pool, 2 dimensional Feature matrix or string - file with dataset.\n",
      " |      \n",
      " |      y : list or numpy.ndarray or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      " |          Labels of the training data.\n",
      " |          If not None, can be a single- or two- dimensional array with numerical values.\n",
      " |          Use only if X is not catboost.Pool and does not point to a file.\n",
      " |      \n",
      " |      cat_features : list or numpy.ndarray, optional (default=None)\n",
      " |          If not None, giving the list of Categ columns indices.\n",
      " |          Use only if X is not catboost.Pool.\n",
      " |      \n",
      " |      text_features : list or numpy.ndarray, optional (default=None)\n",
      " |          If not None, giving the list of Text columns indices.\n",
      " |          Use only if X is not catboost.Pool.\n",
      " |      \n",
      " |      embedding_features : list or numpy.ndarray, optional (default=None)\n",
      " |          If not None, giving the list of Embedding columns indices.\n",
      " |          Use only if X is not catboost.Pool.\n",
      " |      \n",
      " |      graph : list or numpy.ndarray or pandas.DataFrame\n",
      " |          The graph edges list description.\n",
      " |          If list or numpy.ndarrays or pandas.DataFrame, giving 2 dimensional.\n",
      " |      \n",
      " |      sample_weight : list or numpy.ndarray or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      " |          Instance weights, 1 dimensional array like.\n",
      " |      \n",
      " |      baseline : list or numpy.ndarray, optional (default=None)\n",
      " |          If not None, giving 2 dimensional array like data.\n",
      " |          Use only if X is not catboost.Pool.\n",
      " |      \n",
      " |      use_best_model : bool, optional (default=None)\n",
      " |          Flag to use best model\n",
      " |      \n",
      " |      eval_set : catboost.Pool or list of catboost.Pool or tuple (X, y) or list [(X, y)], optional (default=None)\n",
      " |          Validation dataset or datasets for metrics calculation and possibly early stopping.\n",
      " |      \n",
      " |      metric_period : int\n",
      " |          Frequency of evaluating metrics.\n",
      " |      \n",
      " |      verbose : bool or int\n",
      " |          If verbose is bool, then if set to True, logging_level is set to Verbose,\n",
      " |          if set to False, logging_level is set to Silent.\n",
      " |          If verbose is int, it determines the frequency of writing metrics to output and\n",
      " |          logging_level is set to Verbose.\n",
      " |      \n",
      " |      silent : bool\n",
      " |          If silent is True, logging_level is set to Silent.\n",
      " |          If silent is False, logging_level is set to Verbose.\n",
      " |      \n",
      " |      logging_level : string, optional (default=None)\n",
      " |          Possible values:\n",
      " |              - 'Silent'\n",
      " |              - 'Verbose'\n",
      " |              - 'Info'\n",
      " |              - 'Debug'\n",
      " |      \n",
      " |      plot : bool, optional (default=False)\n",
      " |          If True, draw train and eval error in Jupyter notebook\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save train and eval error graphs to file (requires installed plotly)\n",
      " |      \n",
      " |      verbose_eval : bool or int\n",
      " |          Synonym for verbose. Only one of these parameters should be set.\n",
      " |      \n",
      " |      early_stopping_rounds : int\n",
      " |          Activates Iter overfitting detector with od_wait set to early_stopping_rounds.\n",
      " |      \n",
      " |      save_snapshot : bool, [default=None]\n",
      " |          Enable progress snapshotting for restoring progress after crashes or interruptions\n",
      " |      \n",
      " |      snapshot_file : string or pathlib.Path, [default=None]\n",
      " |          Learn progress snapshot file path, if None will use default filename\n",
      " |      \n",
      " |      snapshot_interval: int, [default=600]\n",
      " |          Interval between saving snapshots (seconds)\n",
      " |      \n",
      " |      init_model : CatBoost class or string or pathlib.Path, [default=None]\n",
      " |          Continue training starting from the existing model.\n",
      " |          If this parameter is a string or pathlib.Path, load initial model from the path specified by this string.\n",
      " |      \n",
      " |      callbacks : list, optional (default=None)\n",
      " |          List of callback objects that are applied at end of each iteration.\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      model : CatBoost\n",
      " |  \n",
      " |  predict(self, data, prediction_type=None, ntree_start=0, ntree_end=0, thread_count=-1, verbose=None, task_type='CPU')\n",
      " |      Predict with data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      prediction_type : string, optional (default='RawFormulaVal')\n",
      " |          Can be:\n",
      " |          - 'RawFormulaVal' : return raw formula value.\n",
      " |          - 'Exponent' : return Exponent of raw formula value.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool\n",
      " |          If True, writes the evaluation metric measured set to stderr.\n",
      " |      \n",
      " |      task_type : string, [default=None]\n",
      " |          The evaluator type.\n",
      " |          Possible values:\n",
      " |              - 'CPU'\n",
      " |              - 'GPU' (models with only numerical features are supported for now)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction :\n",
      " |          If data is for a single object, the return value is single float formula return value\n",
      " |          otherwise one-dimensional numpy.ndarray of formula return values for each object.\n",
      " |  \n",
      " |  score(self, X, y=None)\n",
      " |      Calculate R^2.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : catboost.Pool or list or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |          Data to apply model on.\n",
      " |      y : list or numpy.ndarray\n",
      " |          True labels.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      R^2 : float\n",
      " |  \n",
      " |  staged_predict(self, data, prediction_type='RawFormulaVal', ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, verbose=None)\n",
      " |      Predict target at each stage for data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      eval_period: int, optional (default=1)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool\n",
      " |          If True, writes the evaluation metric measured set to stderr.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction : generator for each iteration that generates:\n",
      " |          If data is for a single object, the return value is single float formula return value\n",
      " |          otherwise one-dimensional numpy.ndarray of formula return values for each object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from CatBoost:\n",
      " |  \n",
      " |  calc_feature_statistics(self, data, target=None, feature=None, prediction_type=None, cat_feature_values=None, plot=True, max_cat_features_on_plot=10, thread_count=-1, plot_file=None)\n",
      " |      Get statistics for the feature using the model, dataset and target.\n",
      " |      To use this function, you should install plotly.\n",
      " |      \n",
      " |      The catboost model has borders for the float features used in it. The borders divide\n",
      " |      feature values into bins, and the model's prediction depends on the number of the bin where the\n",
      " |      feature value falls in.\n",
      " |      \n",
      " |      For float features this function takes model's borders and computes\n",
      " |      1) Mean target value for every bin;\n",
      " |      2) Mean model prediction for every bin;\n",
      " |      3) The number of objects in dataset which fall into each bin;\n",
      " |      4) Predictions on varying feature. For every object, varies the feature value\n",
      " |      so that it falls into bin #0, bin #1, ... and counts model predictions.\n",
      " |      Then counts average prediction for each bin.\n",
      " |      \n",
      " |      For categorical features (only one-hot supported) does the same, but takes feature values\n",
      " |      provided in cat_feature_values instead of borders.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data: numpy.ndarray or pandas.DataFrame or catboost. Pool or dict {'pool_name': pool} if you want several pools\n",
      " |          Data to compute statistics on\n",
      " |      target: numpy.ndarray or pandas.Series or dict {'pool_name': target} if you want several pools or None\n",
      " |          Target corresponding to data\n",
      " |          Use only if data is not catboost.Pool.\n",
      " |      feature: None, int, string, or list of int or strings\n",
      " |          Features indexes or names in pd.DataFrame for which you want to get statistics.\n",
      " |          None, if you need statistics for all features.\n",
      " |      prediction_type: str\n",
      " |          Prediction type used for counting mean_prediction: 'Class', 'Probability' or 'RawFormulaVal'.\n",
      " |          If not specified, is derived from the model.\n",
      " |      cat_feature_values: list or numpy.ndarray or pandas.Series or\n",
      " |                          dict: int or string to list or numpy.ndarray or pandas.Series\n",
      " |          Contains categorical feature values you need to get statistics on.\n",
      " |          Use dict, when parameter 'feature' is a list to specify cat values for different features.\n",
      " |          When parameter 'feature' is int or str, you can just pass list of cat values.\n",
      " |      plot: bool\n",
      " |          Plot statistics.\n",
      " |      max_cat_features_on_plot: int\n",
      " |          If categorical feature takes more than max_cat_features_on_plot different unique values,\n",
      " |          output result on several plots, not more than max_cat_features_on_plot feature values on each.\n",
      " |          Used only if plot=True or plot_file is not None.\n",
      " |      thread_count: int\n",
      " |          Number of threads to use for getting statistics.\n",
      " |      plot_file: str\n",
      " |          Output file for plot statistics.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict if parameter 'feature' is int or string, else dict of dicts:\n",
      " |          For each unique feature contain\n",
      " |          python dict with binarized feature statistics.\n",
      " |          For float feature, includes\n",
      " |                  'borders' -- borders for the specified feature in model\n",
      " |                  'binarized_feature' -- numbers of bins where feature values fall\n",
      " |                  'mean_target' -- mean value of target over each bin\n",
      " |                  'mean_prediction' -- mean value of model prediction over each bin\n",
      " |                  'objects_per_bin' -- number of objects per bin\n",
      " |                  'predictions_on_varying_feature' -- averaged over dataset predictions for\n",
      " |                  varying feature (see above)\n",
      " |          For one-hot feature, returns the same, but with 'cat_values' instead of 'borders'\n",
      " |  \n",
      " |  calc_leaf_indexes(self, data, ntree_start=0, ntree_end=0, thread_count=-1, verbose=False)\n",
      " |      Returns indexes of leafs to which objects from pool are mapped by model trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Index of first tree for which leaf indexes will be calculated (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Index of the tree after last tree for which leaf indexes will be calculated (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool (default=False)\n",
      " |          Enable debug logging level.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      leaf_indexes : 2-dimensional numpy.ndarray of numpy.uint32 with shape (object count, ntree_end - ntree_start).\n",
      " |          i-th row is an array of leaf indexes for i-th object.\n",
      " |  \n",
      " |  compare(self, model, data, metrics, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, tmp_dir=None, plot_file=None, log_cout=None, log_cerr=None)\n",
      " |      Draw train and eval errors in Jupyter notebook for both models\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      model: CatBoost model\n",
      " |          Another model to draw metrics\n",
      " |      \n",
      " |      data : catboost.Pool\n",
      " |          Data to evaluate metrics on.\n",
      " |      \n",
      " |      metrics : list of strings or catboost.metrics.BuiltinMetric\n",
      " |          List of evaluated metrics.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      eval_period: int, optional (default=1)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      tmp_dir : string or pathlib.Path (default=None)\n",
      " |          The name of the temporary directory for intermediate results.\n",
      " |          If None, then the name will be generated.\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save eval error graphs to file\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |  \n",
      " |  create_metric_calcer(self, metrics, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, tmp_dir=None)\n",
      " |      Create batch metric calcer. Could be used to aggregate metric on several pools\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |          Same as in eval_metrics except data\n",
      " |      Returns\n",
      " |      -------\n",
      " |          BatchMetricCalcer object\n",
      " |      \n",
      " |      Usage example\n",
      " |      -------\n",
      " |      # Large dataset is partitioned into parts [part1, part2]\n",
      " |      model.fit(params)\n",
      " |      batch_calcer = model.create_metric_calcer(['Logloss'])\n",
      " |      batch_calcer.add(part1)\n",
      " |      batch_calcer.add(part2)\n",
      " |      metrics = batch_calcer.eval_metrics()\n",
      " |  \n",
      " |  drop_unused_features(self)\n",
      " |      Drop unused features information from model\n",
      " |  \n",
      " |  eval_metrics(self, data, metrics, ntree_start=0, ntree_end=0, eval_period=1, thread_count=-1, tmp_dir=None, plot=False, plot_file=None, log_cout=None, log_cerr=None)\n",
      " |      Calculate metrics.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool\n",
      " |          Data to evaluate metrics on.\n",
      " |      \n",
      " |      metrics : list of strings or catboost.metrics.BuiltinMetric\n",
      " |          List of evaluated metrics.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      eval_period: int, optional (default=1)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) with the step eval_period (zero-based indexing).\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      tmp_dir : string or pathlib.Path (default=None)\n",
      " |          The name of the temporary directory for intermediate results.\n",
      " |          If None, then the name will be generated.\n",
      " |      \n",
      " |      plot : bool, optional (default=False)\n",
      " |          If True, draw train and eval error in Jupyter notebook\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save train and eval error graphs to file\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction : dict: metric -> array of shape [(ntree_end - ntree_start) / eval_period]\n",
      " |  \n",
      " |  get_all_params(self)\n",
      " |      Get all params (specified by user and default params) that were set in training from CatBoost model.\n",
      " |      Full parameters documentation could be found here: https://catboost.ai/docs/concepts/python-reference_parameters-list.html\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : dict\n",
      " |          Dictionary of {param_key: param_value}.\n",
      " |  \n",
      " |  get_borders(self)\n",
      " |      Return map feature_index: borders for float features.\n",
      " |  \n",
      " |  get_cat_feature_indices(self)\n",
      " |  \n",
      " |  get_embedding_feature_indices(self)\n",
      " |  \n",
      " |  get_feature_importance(self, data=None, type=<EFstrType.FeatureImportance: 2>, prettified=False, thread_count=-1, verbose=False, fstr_type=None, shap_mode='Auto', model_output='Raw', interaction_indices=None, shap_calc_type='Regular', reference_data=None, sage_n_samples=128, sage_batch_size=512, sage_detect_convergence=True, log_cout=None, log_cerr=None)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data :\n",
      " |          Data to get feature importance.\n",
      " |          If type in ('LossFunctionChange', 'ShapValues', 'ShapInteractionValues') data must of Pool type.\n",
      " |              For every object in this dataset feature importances will be calculated.\n",
      " |          if type == 'SageValues' data must of Pool type.\n",
      " |              For every feature in this dataset importance will be calculated.\n",
      " |          If type == 'PredictionValuesChange', data is None or a dataset of Pool type\n",
      " |              Dataset specification is needed only in case if the model does not contain leaf weight information (trained with CatBoost v < 0.9).\n",
      " |          If type == 'PredictionDiff' data must contain a matrix of feature values of shape (2, n_features).\n",
      " |              Possible types are catboost.Pool or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData or pandas.SparseDataFrame or scipy.sparse.spmatrix\n",
      " |          If type == 'FeatureImportance'\n",
      " |              See 'PredictionValuesChange' for non-ranking metrics and 'LossFunctionChange' for ranking metrics.\n",
      " |          If type == 'Interaction'\n",
      " |              This parameter is not used.\n",
      " |      \n",
      " |      type : EFstrType or string (converted to EFstrType), optional\n",
      " |                  (default=EFstrType.FeatureImportance)\n",
      " |          Possible values:\n",
      " |              - PredictionValuesChange\n",
      " |                  Calculate score for every feature.\n",
      " |              - LossFunctionChange\n",
      " |                  Calculate score for every feature by loss.\n",
      " |              - FeatureImportance\n",
      " |                  PredictionValuesChange for non-ranking metrics and LossFunctionChange for ranking metrics\n",
      " |              - ShapValues\n",
      " |                  Calculate SHAP Values for every object.\n",
      " |              - ShapInteractionValues\n",
      " |                  Calculate SHAP Interaction Values between each pair of features for every object\n",
      " |              - Interaction\n",
      " |                  Calculate pairwise score between every feature.\n",
      " |              - PredictionDiff\n",
      " |                  Calculate most important features explaining difference in predictions for a pair of documents.\n",
      " |              - SageValues\n",
      " |                  Calculate SAGE value for every feature\n",
      " |      \n",
      " |      prettified : bool, optional (default=False)\n",
      " |          change returned data format to the list of (feature_id, importance) pairs sorted by importance\n",
      " |      \n",
      " |      thread_count : int, optional (default=-1)\n",
      " |          Number of threads.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool or int\n",
      " |          If False, then evaluation is not logged. If True, then each possible iteration is logged.\n",
      " |          If a positive integer, then it stands for the size of batch N. After processing each batch, print progress\n",
      " |          and remaining time.\n",
      " |      \n",
      " |      fstr_type : string, deprecated, use type instead\n",
      " |      \n",
      " |      shap_mode : string, optional (default=\"Auto\")\n",
      " |          used only for ShapValues type\n",
      " |          Possible values:\n",
      " |              - \"Auto\"\n",
      " |                  Use direct SHAP Values calculation only if data size is smaller than average leaves number\n",
      " |                  (the best of two strategies below is chosen).\n",
      " |              - \"UsePreCalc\"\n",
      " |                  Calculate SHAP Values for every leaf in preprocessing. Final complexity is\n",
      " |                  O(NT(D+F))+O(TL^2 D^2) where N is the number of documents(objects), T - number of trees,\n",
      " |                  D - average tree depth, F - average number of features in tree, L - average number of leaves in tree\n",
      " |                  This is much faster (because of a smaller constant) than direct calculation when N >> L\n",
      " |              - \"NoPreCalc\"\n",
      " |                  Use direct SHAP Values calculation calculation with complexity O(NTLD^2). Direct algorithm\n",
      " |                  is faster when N < L (algorithm from https://arxiv.org/abs/1802.03888)\n",
      " |      \n",
      " |      shap_calc_type : EShapCalcType or string, optional (default=\"Regular\")\n",
      " |          used only for ShapValues type\n",
      " |          Possible values:\n",
      " |              - \"Regular\"\n",
      " |                  Calculate regular SHAP values\n",
      " |              - \"Approximate\"\n",
      " |                  Calculate approximate SHAP values\n",
      " |              - \"Exact\"\n",
      " |                  Calculate exact SHAP values\n",
      " |      \n",
      " |      interaction_indices : list of int or string (feature_idx_1, feature_idx_2), optional (default=None)\n",
      " |          used only for ShapInteractionValues type\n",
      " |          Calculate SHAP Interaction Values between pair of features feature_idx_1 and feature_idx_2 for every object\n",
      " |      \n",
      " |      reference_data: catboost.Pool or None\n",
      " |          Reference data for Independent Tree SHAP values from https://arxiv.org/abs/1905.04610v1\n",
      " |          if type == 'ShapValues' and reference_data is not None, then Independent Tree SHAP values are calculated\n",
      " |      \n",
      " |      sage_n_samples: int, optional (default=32)\n",
      " |          Number of outer samples used in SAGE values approximation algorithm\n",
      " |      sage_batch_size: int, optional (default=min(512, number of samples in dataset))\n",
      " |          Number of samples used on each step of SAGE values approximation algorithm\n",
      " |      sage_detect_convergence: bool, optional (default=False)\n",
      " |          If set True, sage values calculation will be stopped either when sage values converge\n",
      " |          or when sage_n_samples iterations of algorithm pass\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      depends on type:\n",
      " |          - FeatureImportance\n",
      " |              See PredictionValuesChange for non-ranking metrics and LossFunctionChange for ranking metrics.\n",
      " |          - PredictionValuesChange, LossFunctionChange, PredictionDiff, SageValues with prettified=False (default)\n",
      " |              list of length [n_features] with feature_importance values (float) for feature\n",
      " |          - PredictionValuesChange, LossFunctionChange, PredictionDiff, SageValues with prettified=True\n",
      " |              list of length [n_features] with (feature_id (string), feature_importance (float)) pairs, sorted by feature_importance in descending order\n",
      " |          - ShapValues\n",
      " |              np.ndarray of shape (n_objects, n_features + 1) with Shap values (float) for (object, feature).\n",
      " |              In case of multiclass the returned value is np.ndarray of shape\n",
      " |              (n_objects, classes_count, n_features + 1). For each object it contains Shap values (float).\n",
      " |              Values are calculated for RawFormulaVal predictions.\n",
      " |          - ShapInteractionValues\n",
      " |              np.ndarray of shape (n_objects, n_features + 1, n_features + 1) with Shap interaction values (float) for (object, feature(i), feature(j)).\n",
      " |              In case of multiclass the returned value is np.ndarray of shape\n",
      " |              (n_objects, classes_count, n_features + 1, n_features + 1). For each object it contains Shap interaction values (float).\n",
      " |              Values are calculated for RawFormulaVal predictions.\n",
      " |          - Interaction\n",
      " |              list of length [n_features] of 3-element lists of (first_feature_index, second_feature_index, interaction_score (float))\n",
      " |  \n",
      " |  get_object_importance(self, pool, train_pool, top_size=-1, type='Average', update_method='SinglePoint', importance_values_sign='All', thread_count=-1, verbose=False, ostr_type=None, log_cout=None, log_cerr=None)\n",
      " |      This is the implementation of the LeafInfluence algorithm from the following paper:\n",
      " |      https://arxiv.org/pdf/1802.06640.pdf\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      pool : Pool\n",
      " |          The pool for which you want to evaluate the object importances.\n",
      " |      \n",
      " |      train_pool : Pool\n",
      " |          The pool on which the model has been trained.\n",
      " |      \n",
      " |      top_size : int (default=-1)\n",
      " |          Method returns the result of the top_size most important train objects.\n",
      " |          If -1, then the top size is not limited.\n",
      " |      \n",
      " |      type : string, optional (default='Average')\n",
      " |          Possible values:\n",
      " |              - Average (Method returns the mean train objects scores for all input objects)\n",
      " |              - PerObject (Method returns the train objects scores for every input object)\n",
      " |      \n",
      " |      importance_values_sign : string, optional (default='All')\n",
      " |          Method returns only Positive, Negative or All values.\n",
      " |          Possible values:\n",
      " |              - Positive\n",
      " |              - Negative\n",
      " |              - All\n",
      " |      \n",
      " |      update_method : string, optional (default='SinglePoint')\n",
      " |          Possible values:\n",
      " |              - SinglePoint\n",
      " |              - TopKLeaves (It is posible to set top size : TopKLeaves:top=2)\n",
      " |              - AllPoints\n",
      " |          Description of the update set methods are given in section 3.1.3 of the paper.\n",
      " |      \n",
      " |      thread_count : int, optional (default=-1)\n",
      " |          Number of threads.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool or int\n",
      " |          If False, then evaluation is not logged. If True, then each possible iteration is logged.\n",
      " |          If a positive integer, then it stands for the size of batch N. After processing each batch, print progress\n",
      " |          and remaining time.\n",
      " |      \n",
      " |      ostr_type : string, deprecated, use type instead\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      object_importances : tuple of two arrays (indices and scores) of shape = [top_size]\n",
      " |  \n",
      " |  get_param(self, key)\n",
      " |      Get param value from CatBoost model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      key : string\n",
      " |          The key to get param value from.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      value :\n",
      " |          The param value of the key, returns None if param do not exist.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get all params from CatBoost model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      result : dict\n",
      " |          Dictionary of {param_key: param_value}.\n",
      " |  \n",
      " |  get_text_feature_indices(self)\n",
      " |  \n",
      " |  grid_search(self, param_grid, X, y=None, cv=3, partition_random_seed=0, calc_cv_statistics=True, search_by_train_test_split=True, refit=True, shuffle=True, stratified=None, train_size=0.8, verbose=True, plot=False, plot_file=None, log_cout=None, log_cerr=None)\n",
      " |      Exhaustive search over specified parameter values for a model.\n",
      " |      After calling this method model is fitted and can be used, if not specified otherwise (refit=False).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      param_grid: dict or list of dictionaries\n",
      " |          Dictionary with parameters names (string) as keys and lists of parameter settings\n",
      " |          to try as values, or a list of such dictionaries, in which case the grids spanned by each\n",
      " |          dictionary in the list are explored.\n",
      " |          This enables searching over any sequence of parameter settings.\n",
      " |      \n",
      " |      X: numpy.ndarray or pandas.DataFrame or catboost.Pool\n",
      " |          Data to compute statistics on\n",
      " |      \n",
      " |      y: list or numpy.ndarray or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      " |          Labels of the training data.\n",
      " |          If not None, can be a single- or two- dimensional array with either:\n",
      " |            - numerical values - for regression (including multiregression), ranking and binary classification problems\n",
      " |            - class labels (boolean, integer or string) - for classification (including multiclassification) problems\n",
      " |          Use only if X is not catboost.Pool and does not point to a file.\n",
      " |      \n",
      " |      cv: int, cross-validation generator or an iterable, optional (default=None)\n",
      " |          Determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
      " |          - None, to use the default 3-fold cross validation,\n",
      " |          - integer, to specify the number of folds in a (Stratified)KFold\n",
      " |          - one of the scikit-learn splitter classes\n",
      " |              (https://scikit-learn.org/stable/modules/classes.html#splitter-classes)\n",
      " |          - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |      \n",
      " |      partition_random_seed: int, optional (default=0)\n",
      " |          Use this as the seed value for random permutation of the data.\n",
      " |          Permutation is performed before splitting the data for cross validation.\n",
      " |          Each seed generates unique data splits.\n",
      " |          Used only when cv is None or int.\n",
      " |      \n",
      " |      search_by_train_test_split: bool, optional (default=True)\n",
      " |          If True, source dataset is splitted into train and test parts, models are trained\n",
      " |          on the train part and parameters are compared by loss function score on the test part.\n",
      " |          After that, if calc_cv_statistics=true, statistics on metrics are calculated\n",
      " |          using cross-validation using best parameters and the model is fitted with these parameters.\n",
      " |      \n",
      " |          If False, every iteration of grid search evaluates results on cross-validation.\n",
      " |          It is recommended to set parameter to True for large datasets, and to False for small datasets.\n",
      " |      \n",
      " |      calc_cv_statistics: bool, optional (default=True)\n",
      " |          The parameter determines whether quality should be estimated.\n",
      " |          using cross-validation with the found best parameters. Used only when search_by_train_test_split=True.\n",
      " |      \n",
      " |      refit: bool (default=True)\n",
      " |          Refit an estimator using the best found parameters on the whole dataset.\n",
      " |      \n",
      " |      shuffle: bool, optional (default=True)\n",
      " |          Shuffle the dataset objects before parameters searching.\n",
      " |      \n",
      " |      stratified: bool, optional (default=None)\n",
      " |          Perform stratified sampling. True for classification and False otherwise.\n",
      " |          Currently supported only for final cross-validation.\n",
      " |      \n",
      " |      train_size: float, optional (default=0.8)\n",
      " |          Should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split.\n",
      " |      \n",
      " |      verbose: bool or int, optional (default=True)\n",
      " |          If verbose is int, it determines the frequency of writing metrics to output\n",
      " |          verbose==True is equal to verbose==1\n",
      " |          When verbose==False, there is no messages\n",
      " |      \n",
      " |      plot : bool, optional (default=False)\n",
      " |          If True, draw train and eval error for every set of parameters in Jupyter notebook\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save train and eval error for every set of parameters to file\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict with two fields:\n",
      " |          'params': dict of best found parameters\n",
      " |          'cv_results': dict or pandas.core.frame.DataFrame with cross-validation results\n",
      " |              columns are: test-error-mean  test-error-std  train-error-mean  train-error-std\n",
      " |  \n",
      " |  iterate_leaf_indexes(self, data, ntree_start=0, ntree_end=0)\n",
      " |      Returns indexes of leafs to which objects from pool are mapped by model trees.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Index of first tree for which leaf indexes will be calculated (zero-based indexing).\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Index of the tree after last tree for which leaf indexes will be calculated (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      leaf_indexes : generator. For each object in pool yields one-dimensional numpy.ndarray of leaf indexes.\n",
      " |  \n",
      " |  load_model(self, fname=None, format='cbm', stream=None, blob=None)\n",
      " |      Load model from a file, stream or blob.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string\n",
      " |          Input file name.\n",
      " |  \n",
      " |  plot_partial_dependence(self, data, features, plot=True, plot_file=None, thread_count=-1)\n",
      " |      To use this function, you should install plotly.\n",
      " |      data: numpy.ndarray or pandas.DataFrame or catboost.Pool\n",
      " |      features: int, str, list<int>, tuple<int>, list<string>, tuple<string>\n",
      " |          Float features to calculate partial dependence for. Number of features should be 1 or 2.\n",
      " |      plot: bool\n",
      " |          Plot predictions.\n",
      " |      plot_file: str\n",
      " |          Output file for plot predictions.\n",
      " |      thread_count: int\n",
      " |          Number of threads to use. If -1 use maximum available number of threads.\n",
      " |      Returns\n",
      " |      -------\n",
      " |          If number of features is one - 1d numpy array and figure with line plot.\n",
      " |          If number of features is two - 2d numpy array and figure with 2d heatmap.\n",
      " |  \n",
      " |  plot_predictions(self, data, features_to_change, plot=True, plot_file=None)\n",
      " |      To use this function, you should install plotly.\n",
      " |      \n",
      " |      data: numpy.ndarray or pandas.DataFrame or catboost.Pool\n",
      " |      features_to_change: list-like with int (for indices) or str (for names) elements\n",
      " |          Numerical features indices or names in `data` for which you want to vary prediction value.\n",
      " |      plot: bool\n",
      " |          Plot predictions.\n",
      " |      plot_file: str\n",
      " |          Output file for plot predictions.\n",
      " |      Returns\n",
      " |      -------\n",
      " |          List of list of predictions for all buckets for all samples in data\n",
      " |  \n",
      " |  plot_tree(self, tree_idx, pool=None)\n",
      " |  \n",
      " |  randomized_search(self, param_distributions, X, y=None, cv=3, n_iter=10, partition_random_seed=0, calc_cv_statistics=True, search_by_train_test_split=True, refit=True, shuffle=True, stratified=None, train_size=0.8, verbose=True, plot=False, plot_file=None, log_cout=None, log_cerr=None)\n",
      " |      Randomized search on hyper parameters.\n",
      " |      After calling this method model is fitted and can be used, if not specified otherwise (refit=False).\n",
      " |      \n",
      " |      In contrast to grid_search, not all parameter values are tried out,\n",
      " |      but rather a fixed number of parameter settings is sampled from the specified distributions.\n",
      " |      The number of parameter settings that are tried is given by n_iter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      param_distributions: dict\n",
      " |          Dictionary with parameters names (string) as keys and distributions or lists of parameters to try.\n",
      " |          Distributions must provide a rvs method for sampling (such as those from scipy.stats.distributions).\n",
      " |          If a list is given, it is sampled uniformly.\n",
      " |      \n",
      " |      X: numpy.ndarray or pandas.DataFrame or catboost.Pool\n",
      " |          Data to compute statistics on\n",
      " |      \n",
      " |      y: list or numpy.ndarray or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      " |          Labels of the training data.\n",
      " |          If not None, can be a single- or two- dimensional array with either:\n",
      " |            - numerical values - for regression (including multiregression), ranking and binary classification problems\n",
      " |            - class labels (boolean, integer or string) - for classification (including multiclassification) problems\n",
      " |          Use only if X is not catboost.Pool and does not point to a file.\n",
      " |      \n",
      " |      cv: int, cross-validation generator or an iterable, optional (default=None)\n",
      " |          Determines the cross-validation splitting strategy. Possible inputs for cv are:\n",
      " |          - None, to use the default 3-fold cross validation,\n",
      " |          - integer, to specify the number of folds in a (Stratified)KFold\n",
      " |          - one of the scikit-learn splitter classes\n",
      " |              (https://scikit-learn.org/stable/modules/classes.html#splitter-classes)\n",
      " |          - An iterable yielding (train, test) splits as arrays of indices.\n",
      " |      \n",
      " |      n_iter: int\n",
      " |          Number of parameter settings that are sampled.\n",
      " |          n_iter trades off runtime vs quality of the solution.\n",
      " |      \n",
      " |      partition_random_seed: int, optional (default=0)\n",
      " |          Use this as the seed value for random permutation of the data.\n",
      " |          Permutation is performed before splitting the data for cross validation.\n",
      " |          Each seed generates unique data splits.\n",
      " |          Used only when cv is None or int.\n",
      " |      \n",
      " |      search_by_train_test_split: bool, optional (default=True)\n",
      " |          If True, source dataset is splitted into train and test parts, models are trained\n",
      " |          on the train part and parameters are compared by loss function score on the test part.\n",
      " |          After that, if calc_cv_statistics=true, statistics on metrics are calculated\n",
      " |          using cross-validation using best parameters and the model is fitted with these parameters.\n",
      " |      \n",
      " |          If False, every iteration of grid search evaluates results on cross-validation.\n",
      " |          It is recommended to set parameter to True for large datasets, and to False for small datasets.\n",
      " |      \n",
      " |      calc_cv_statistics: bool, optional (default=True)\n",
      " |          The parameter determines whether quality should be estimated.\n",
      " |          using cross-validation with the found best parameters. Used only when search_by_train_test_split=True.\n",
      " |      \n",
      " |      refit: bool (default=True)\n",
      " |          Refit an estimator using the best found parameters on the whole dataset.\n",
      " |      \n",
      " |      shuffle: bool, optional (default=True)\n",
      " |          Shuffle the dataset objects before parameters searching.\n",
      " |      \n",
      " |      stratified: bool, optional (default=None)\n",
      " |          Perform stratified sampling. True for classification and False otherwise.\n",
      " |          Currently supported only for cross-validation.\n",
      " |      \n",
      " |      train_size: float, optional (default=0.8)\n",
      " |          Should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the train split.\n",
      " |      \n",
      " |      verbose: bool or int, optional (default=True)\n",
      " |          If verbose is int, it determines the frequency of writing metrics to output\n",
      " |          verbose==True is equal to verbose==1\n",
      " |          When verbose==False, there is no messages\n",
      " |      \n",
      " |      plot : bool, optional (default=False)\n",
      " |          If True, draw train and eval error for every set of parameters in Jupyter notebook\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save train and eval error for every set of parameters to file\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict with two fields:\n",
      " |          'params': dict of best found parameters\n",
      " |          'cv_results': dict or pandas.core.frame.DataFrame with cross-validation results\n",
      " |              columns are: test-error-mean  test-error-std  train-error-mean  train-error-std\n",
      " |  \n",
      " |  save_borders(self, fname)\n",
      " |      Save the model borders to a file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string or pathlib.Path\n",
      " |          Output file name.\n",
      " |  \n",
      " |  save_model(self, fname, format='cbm', export_parameters=None, pool=None)\n",
      " |      Save the model to a file.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : string\n",
      " |          Output file name.\n",
      " |      format : string\n",
      " |          Possible values:\n",
      " |              * 'cbm' for catboost binary format,\n",
      " |              * 'coreml' to export into Apple CoreML format\n",
      " |              * 'onnx' to export into ONNX-ML format\n",
      " |              * 'pmml' to export into PMML format\n",
      " |              * 'cpp' to export as C++ code\n",
      " |              * 'python' to export as Python code.\n",
      " |      export_parameters : dict\n",
      " |          Parameters for CoreML export:\n",
      " |              * prediction_type : string - either 'probability' or 'raw'\n",
      " |              * coreml_description : string\n",
      " |              * coreml_model_version : string\n",
      " |              * coreml_model_author : string\n",
      " |              * coreml_model_license: string\n",
      " |          Parameters for PMML export:\n",
      " |              * pmml_copyright : string\n",
      " |              * pmml_description : string\n",
      " |              * pmml_model_version : string\n",
      " |      pool : catboost.Pool or list or numpy.ndarray or pandas.DataFrame or pandas.Series or catboost.FeaturesData\n",
      " |          Training pool.\n",
      " |  \n",
      " |  select_features(self, X, y=None, eval_set=None, features_for_select=None, num_features_to_select=None, algorithm=None, steps=None, shap_calc_type=None, train_final_model=True, verbose=None, logging_level=None, plot=False, plot_file=None, log_cout=None, log_cerr=None, grouping=None, features_tags_for_select=None, num_features_tags_to_select=None)\n",
      " |      Select best features from pool according to loss value.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : catboost.Pool or list or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |          If not catboost.Pool, 2 dimensional Feature matrix or string - file with dataset.\n",
      " |      \n",
      " |      y : list or numpy.ndarray or pandas.DataFrame or pandas.Series, optional (default=None)\n",
      " |          Labels of the training data.\n",
      " |          If not None, can be a single- or two- dimensional array with either:\n",
      " |            - numerical values - for regression (including multiregression), ranking and binary classification problems\n",
      " |            - class labels (boolean, integer or string) - for classification (including multiclassification) problems\n",
      " |          Use only if X is not catboost.Pool and does not point to a file.\n",
      " |      \n",
      " |      eval_set : catboost.Pool or list of catboost.Pool or tuple (X, y) or list [(X, y)], optional (default=None)\n",
      " |          Validation dataset or datasets for metrics calculation and possibly early stopping.\n",
      " |      \n",
      " |      features_for_select : str or list of feature indices, names or ranges\n",
      " |          (for grouping = Individual)\n",
      " |          Which features should participate in the selection.\n",
      " |          Format examples:\n",
      " |              - [0, 2, 3, 4, 17]\n",
      " |              - [0, \"2-4\", 17] (both ends in ranges are inclusive)\n",
      " |              - \"0,2-4,20\"\n",
      " |              - [\"Name0\", \"Name2\", \"Name3\", \"Name4\", \"Name20\"]\n",
      " |      \n",
      " |      num_features_to_select : positive int\n",
      " |          (for grouping = Individual)\n",
      " |          How many features to select from features_for_select.\n",
      " |      \n",
      " |      algorithm : EFeaturesSelectionAlgorithm or string, optional (default=RecursiveByShapValues)\n",
      " |          Which algorithm to use for features selection.\n",
      " |          Possible values:\n",
      " |              - RecursiveByPredictionValuesChange\n",
      " |                  Use prediction values change as feature strength, eliminate batch of features at once.\n",
      " |              - RecursiveByLossFunctionChange\n",
      " |                  Use loss function change as feature strength, eliminate batch of features at each step.\n",
      " |              - RecursiveByShapValues\n",
      " |                  Use shap values to estimate loss function change, eliminate features one by one.\n",
      " |      \n",
      " |      steps : positive int, optional (default=1)\n",
      " |          How many steps should be performed. In other words, how many times a full model will be trained.\n",
      " |          More steps give more accurate results.\n",
      " |      \n",
      " |      shap_calc_type : EShapCalcType or string, optional (default=Regular)\n",
      " |          Which method to use for calculation of shap values.\n",
      " |          Possible values:\n",
      " |              - Regular\n",
      " |                  Calculate regular SHAP values\n",
      " |              - Approximate\n",
      " |                  Calculate approximate SHAP values\n",
      " |              - Exact\n",
      " |                  Calculate exact SHAP values\n",
      " |      \n",
      " |      train_final_model : bool, optional (default=True)\n",
      " |          Need to fit model with selected features.\n",
      " |      \n",
      " |      verbose : bool or int\n",
      " |          If verbose is bool, then if set to True, logging_level is set to Verbose,\n",
      " |          if set to False, logging_level is set to Silent.\n",
      " |          If verbose is int, it determines the frequency of writing metrics to output and\n",
      " |          logging_level is set to Verbose.\n",
      " |      \n",
      " |      logging_level : string, optional (default=None)\n",
      " |          Possible values:\n",
      " |              - 'Silent'\n",
      " |              - 'Verbose'\n",
      " |              - 'Info'\n",
      " |              - 'Debug'\n",
      " |      \n",
      " |      plot : bool, optional (default=False)\n",
      " |          If True, draw train and eval error in Jupyter notebook.\n",
      " |      \n",
      " |      plot_file : file-like or str, optional (default=None)\n",
      " |          If not None, save train and eval error graphs to file\n",
      " |      \n",
      " |      log_cout: output stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stdout is used\n",
      " |      \n",
      " |      log_cerr: error stream or callback for logging (default=None)\n",
      " |          If None is specified, sys.stderr is used\n",
      " |      \n",
      " |      grouping : EFeaturesSelectionGrouping or string, optional (default=Individual)\n",
      " |          Which grouping to use for features selection.\n",
      " |          Possible values:\n",
      " |              - Individual\n",
      " |                  Select individual features\n",
      " |              - ByTags\n",
      " |                  Select feature groups (marked by tags)\n",
      " |      \n",
      " |      features_tags_for_select : list of strings\n",
      " |          (for grouping = ByTags)\n",
      " |          Which features tags should participate in the selection.\n",
      " |      \n",
      " |      num_features_tags_to_select : positive int\n",
      " |          (for grouping = ByTags)\n",
      " |          How many features tags to select from features_tags_for_select.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      dict with fields:\n",
      " |          'selected_features': list of selected features indices\n",
      " |          'eliminated_features': list of eliminated features indices\n",
      " |          'selected_features_tags': list of selected features tags (optional, present if grouping == ByTags)\n",
      " |          'eliminated_features_tags': list of selected features tags (optional, present if grouping == ByTags)\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set parameters into CatBoost model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : key=value format\n",
      " |          List of key=value paris. Example: model.set_params(iterations=500, thread_count=2).\n",
      " |  \n",
      " |  shrink(self, ntree_end, ntree_start=0)\n",
      " |      Shrink the model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ntree_end: int\n",
      " |          Leave the trees with indices from the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |      ntree_start: int, optional (default=0)\n",
      " |          Leave the trees with indices from the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |  \n",
      " |  virtual_ensembles_predict(self, data, prediction_type='VirtEnsembles', ntree_end=0, virtual_ensembles_count=10, thread_count=-1, verbose=None)\n",
      " |      Predict with data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      data : catboost.Pool or list of features or list of lists or numpy.ndarray or pandas.DataFrame or pandas.Series\n",
      " |              or catboost.FeaturesData\n",
      " |          Data to apply model on.\n",
      " |          If data is a simple list (not list of lists) or a one-dimensional numpy.ndarray it is interpreted\n",
      " |          as a list of features for a single object.\n",
      " |      \n",
      " |      prediction_type : string, optional (default='RawFormulaVal')\n",
      " |          Can be:\n",
      " |          - 'VirtEnsembles': return V (virtual_ensembles_count) predictions.\n",
      " |              k-th virtEnsemle consists of trees [0, T/2] + [T/2 + T/(2V) * k, T/2 + T/(2V) * (k + 1)]  * constant.\n",
      " |          - 'TotalUncertainty': see returned predictions format in 'Returns' part\n",
      " |      \n",
      " |      ntree_end: int, optional (default=0)\n",
      " |          Model is applied on the interval [ntree_start, ntree_end) (zero-based indexing).\n",
      " |          If value equals to 0 this parameter is ignored and ntree_end equal to tree_count_.\n",
      " |      \n",
      " |      virtual_ensembles_count: int, optional (default=10)\n",
      " |          virtual ensembles count for 'TotalUncertainty' and 'VirtEnsembles' prediction types.\n",
      " |      \n",
      " |      thread_count : int (default=-1)\n",
      " |          The number of threads to use when applying the model.\n",
      " |          Allows you to optimize the speed of execution. This parameter doesn't affect results.\n",
      " |          If -1, then the number of threads is set to the number of CPU cores.\n",
      " |      \n",
      " |      verbose : bool, optional (default=False)\n",
      " |          If True, writes the evaluation metric measured set to stderr.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      prediction :\n",
      " |          (with V as virtual_ensembles_count and T as trees count,\n",
      " |          k-th virtEnsemle consists of trees [0, T/2] + [T/2 + T/(2V) * k, T/2 + T/(2V) * (k + 1)]  * constant)\n",
      " |          If data is for a single object, return 1-dimensional array of predictions with size depends on prediction type,\n",
      " |          otherwise return 2-dimensional numpy.ndarray with shape (number_of_objects x size depends on prediction type);\n",
      " |          Returned predictions depends on prediction type:\n",
      " |          If loss-function was RMSEWithUncertainty:\n",
      " |              - 'VirtEnsembles': [mean0, var0, mean1, var1, ..., vark-1].\n",
      " |              - 'TotalUncertainty': [mean_predict, KnowledgeUnc, DataUnc].\n",
      " |          otherwise for regression:\n",
      " |              - 'VirtEnsembles':  [mean0, mean1, ...].\n",
      " |              - 'TotalUncertainty': [mean_predicts, KnowledgeUnc].\n",
      " |          otherwise for binary classification:\n",
      " |              - 'VirtEnsembles':  [ApproxRawFormulaVal0, ApproxRawFormulaVal1, ..., ApproxRawFormulaValk-1].\n",
      " |              - 'TotalUncertainty':  [DataUnc, TotalUnc].\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from CatBoost:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _CatBoostBase:\n",
      " |  \n",
      " |  __copy__(self)\n",
      " |  \n",
      " |  __deepcopy__(self, _)\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  copy(self)\n",
      " |  \n",
      " |  get_best_iteration(self)\n",
      " |  \n",
      " |  get_best_score(self)\n",
      " |  \n",
      " |  get_evals_result(self)\n",
      " |  \n",
      " |  get_leaf_values(self)\n",
      " |      Returns\n",
      " |      -------\n",
      " |      leaf_values : 1d-array of leaf values for all trees.\n",
      " |      Value corresponding to j-th leaf of i-th tree is at position\n",
      " |      sum(get_tree_leaf_counts()[:i]) + j (leaf and tree indexing starts from zero).\n",
      " |  \n",
      " |  get_leaf_weights(self)\n",
      " |      Returns\n",
      " |      -------\n",
      " |      leaf_weights : 1d-array of leaf weights for all trees.\n",
      " |      Weight of j-th leaf of i-th tree is at position\n",
      " |      sum(get_tree_leaf_counts()[:i]) + j (leaf and tree indexing starts from zero).\n",
      " |  \n",
      " |  get_metadata(self)\n",
      " |  \n",
      " |  get_n_features_in(self)\n",
      " |  \n",
      " |  get_scale_and_bias(self)\n",
      " |  \n",
      " |  get_test_eval(self)\n",
      " |  \n",
      " |  get_test_evals(self)\n",
      " |  \n",
      " |  get_tree_leaf_counts(self)\n",
      " |      Returns\n",
      " |      -------\n",
      " |      tree_leaf_counts : 1d-array of numpy.uint32 of size tree_count_.\n",
      " |      tree_leaf_counts[i] equals to the number of leafs in i-th tree of the ensemble.\n",
      " |  \n",
      " |  is_fitted(self)\n",
      " |  \n",
      " |  set_feature_names(self, feature_names)\n",
      " |      Sets feature names equal to feature_names\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      feature_names: 1-d array of strings with new feature names in the same order as in pool\n",
      " |  \n",
      " |  set_leaf_values(self, new_leaf_values)\n",
      " |      Sets values at tree leafs of ensemble equal to new_leaf_values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      new_leaf_values : 1d-array with new leaf values for all trees.\n",
      " |      It's size should be equal to sum(get_tree_leaf_counts()).\n",
      " |      Value corresponding to j-th leaf of i-th tree should be at position\n",
      " |      sum(get_tree_leaf_counts()[:i]) + j (leaf and tree indexing starts from zero).\n",
      " |  \n",
      " |  set_scale_and_bias(self, scale, bias)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from _CatBoostBase:\n",
      " |  \n",
      " |  best_iteration_\n",
      " |  \n",
      " |  best_score_\n",
      " |  \n",
      " |  classes_\n",
      " |  \n",
      " |  evals_result_\n",
      " |  \n",
      " |  feature_names_\n",
      " |  \n",
      " |  learning_rate_\n",
      " |  \n",
      " |  n_features_in_\n",
      " |  \n",
      " |  random_seed_\n",
      " |  \n",
      " |  tree_count_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _CatBoostBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from _CatBoostBase:\n",
      " |  \n",
      " |  __hash__ = None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(CatBoostRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ad92f65-e1fa-4743-92ff-049d3c9f965c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from ipywidgets) (8.27.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.11.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /Users/daisydu/anaconda3/envs/kKzksw/lib/python3.11/site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: console dejavu events execute kernel kernelspec lab\n",
      "labextension labhub migrate nbconvert notebook run server troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fdf795074c132e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:01.332494Z",
     "start_time": "2024-12-03T08:30:01.325748Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    n_estimators=500, \n",
    "    random_seed=42,\n",
    "    loss_function='MultiClass',  \n",
    "    custom_metric=['AUC', 'Accuracy'],  \n",
    "    logging_level='Silent',  \n",
    "    class_weights=None,  \n",
    "    thread_count=-1 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "871ea56a6989b853",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:03.911378Z",
     "start_time": "2024-12-03T08:30:01.334493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc8e4e96bda43a6b9db8523ef52a542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x303e46390>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_small, y_small, eval_set=(X_small, y_small),plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d6098074e1e8440",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:03.968937Z",
     "start_time": "2024-12-03T08:30:03.912379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.8804\n",
      "Accuracy on valid set: 0.6900\n",
      "Classification Report on train set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      5736\n",
      "           1       0.90      0.87      0.89     10623\n",
      "           2       0.86      0.89      0.87      3641\n",
      "\n",
      "    accuracy                           0.88     20000\n",
      "   macro avg       0.87      0.88      0.88     20000\n",
      "weighted avg       0.88      0.88      0.88     20000\n",
      "\n",
      "Classification Report on valid set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.61      0.65      3210\n",
      "           1       0.72      0.76      0.74      6481\n",
      "           2       0.59      0.61      0.60      2309\n",
      "\n",
      "    accuracy                           0.69     12000\n",
      "   macro avg       0.67      0.66      0.66     12000\n",
      "weighted avg       0.69      0.69      0.69     12000\n",
      "\n",
      "Confusion Matrix on train set:\n",
      " [[5107  595   34]\n",
      " [ 847 9273  503]\n",
      " [   8  405 3228]]\n",
      "Confusion Matrix on valid set:\n",
      " [[1956 1084  170]\n",
      " [ 767 4924  790]\n",
      " [  66  843 1400]]\n"
     ]
    }
   ],
   "source": [
    "print_score(model, X_small, y_small, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a78660a44e913458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:03.974059Z",
     "start_time": "2024-12-03T08:30:03.968937Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_valid.iloc[:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cde74d773494b91f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:03.978569Z",
     "start_time": "2024-12-03T08:30:03.975057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8efe942c93a8fa28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:06.408962Z",
     "start_time": "2024-12-03T08:30:03.979565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 1.0000\n",
      "Accuracy on valid set: 0.6948\n",
      "Classification Report on train set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5736\n",
      "           1       1.00      1.00      1.00     10623\n",
      "           2       1.00      1.00      1.00      3641\n",
      "\n",
      "    accuracy                           1.00     20000\n",
      "   macro avg       1.00      1.00      1.00     20000\n",
      "weighted avg       1.00      1.00      1.00     20000\n",
      "\n",
      "Classification Report on valid set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67      3210\n",
      "           1       0.74      0.74      0.74      6481\n",
      "           2       0.58      0.67      0.62      2309\n",
      "\n",
      "    accuracy                           0.69     12000\n",
      "   macro avg       0.67      0.68      0.67     12000\n",
      "weighted avg       0.70      0.69      0.70     12000\n",
      "\n",
      "Confusion Matrix on train set:\n",
      " [[ 5736     0     0]\n",
      " [    0 10623     0]\n",
      " [    0     0  3641]]\n",
      "Confusion Matrix on valid set:\n",
      " [[2031  977  202]\n",
      " [ 780 4770  931]\n",
      " [  61  711 1537]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "sk_model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    n_jobs=-1, \n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "sk_model.fit(X_small, y_small)\n",
    "print_score(sk_model, X_small, y_small, X_valid, y_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b29d43c1407a4fa",
   "metadata": {},
   "source": [
    "### $\\bullet$ Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a768685e3eada9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:06.413007Z",
     "start_time": "2024-12-03T08:30:06.409959Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    n_estimators=200, \n",
    "    random_seed=42,\n",
    "    learning_rate = 1.0, # learning_rate, eta,\n",
    "    loss_function='MultiClass',  \n",
    "    custom_metric=['AUC', 'Accuracy'],  \n",
    "    logging_level='Silent',  \n",
    "    class_weights=None,  \n",
    "    thread_count=-1 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ded2dfbc7f81a7c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:07.426300Z",
     "start_time": "2024-12-03T08:30:06.413517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7efb02b9893a4259865c9871bf7bc59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x3022bc290>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_small, y_small, plot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3caab1f13756438c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:07.481821Z",
     "start_time": "2024-12-03T08:30:07.426810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.9253\n",
      "Accuracy on valid set: 0.6411\n",
      "Classification Report on train set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92      5736\n",
      "           1       0.94      0.92      0.93     10623\n",
      "           2       0.91      0.93      0.92      3641\n",
      "\n",
      "    accuracy                           0.93     20000\n",
      "   macro avg       0.92      0.93      0.92     20000\n",
      "weighted avg       0.93      0.93      0.93     20000\n",
      "\n",
      "Classification Report on valid set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.57      3210\n",
      "           1       0.68      0.73      0.70      6481\n",
      "           2       0.56      0.53      0.55      2309\n",
      "\n",
      "    accuracy                           0.64     12000\n",
      "   macro avg       0.62      0.60      0.61     12000\n",
      "weighted avg       0.64      0.64      0.64     12000\n",
      "\n",
      "Confusion Matrix on train set:\n",
      " [[5347  377   12]\n",
      " [ 521 9774  328]\n",
      " [  11  245 3385]]\n",
      "Confusion Matrix on valid set:\n",
      " [[1738 1284  188]\n",
      " [ 969 4722  790]\n",
      " [ 132  944 1233]]\n"
     ]
    }
   ],
   "source": [
    "print_score(model, X_small, y_small, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5e837de4fc7f74",
   "metadata": {},
   "source": [
    "Let us now try with a smaller learning rate, and more trees to alleviate :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5ea1d57195b2c20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:07.485624Z",
     "start_time": "2024-12-03T08:30:07.482820Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    n_estimators=5000,  # iterations, n_estimators, num_boost_round, num_trees\n",
    "    random_seed=42,\n",
    "    learning_rate = 0.005, # learning_rate, eta,\n",
    "    loss_function='MultiClass',  \n",
    "    custom_metric=['AUC', 'Accuracy'],  \n",
    "    logging_level='Silent',  \n",
    "    class_weights=None,  \n",
    "    thread_count=-1 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be17e3912aad4bd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:37.431726Z",
     "start_time": "2024-12-03T08:30:07.485624Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e66fd2d73e4cb6b3a191ac1ade4d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x17fac1e50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_small, y_small, plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9affc3189d4563eb",
   "metadata": {},
   "source": [
    "### $\\bullet$ Validation of the number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af5b7448f1047503",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:37.435727Z",
     "start_time": "2024-12-03T08:30:37.432724Z"
    }
   },
   "outputs": [],
   "source": [
    "# see the full list of hyperparameters at \n",
    "# https://catboost.ai/docs/concepts/python-reference_catboostregressor.html#python-reference_catboostregressor\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    n_estimators=500, \n",
    "    random_seed=42,\n",
    "    loss_function='MultiClass',  \n",
    "    custom_metric=['AUC', 'Accuracy'],  \n",
    "    logging_level='Silent',  \n",
    "    class_weights=None,  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6416f285c52f7051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:42.971798Z",
     "start_time": "2024-12-03T08:30:37.435727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c6077a2c694ffcaba80e4a43fda7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x303c39e50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_small, y_small, eval_set = (X_valid, y_valid), plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45d68433c15f8bf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:43.036853Z",
     "start_time": "2024-12-03T08:30:42.972795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.7792\n",
      "Accuracy on valid set: 0.6967\n",
      "Classification Report on train set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76      5736\n",
      "           1       0.81      0.80      0.81     10623\n",
      "           2       0.70      0.78      0.74      3641\n",
      "\n",
      "    accuracy                           0.78     20000\n",
      "   macro avg       0.76      0.77      0.77     20000\n",
      "weighted avg       0.78      0.78      0.78     20000\n",
      "\n",
      "Classification Report on valid set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.66      3210\n",
      "           1       0.73      0.75      0.74      6481\n",
      "           2       0.58      0.65      0.62      2309\n",
      "\n",
      "    accuracy                           0.70     12000\n",
      "   macro avg       0.68      0.67      0.67     12000\n",
      "weighted avg       0.70      0.70      0.70     12000\n",
      "\n",
      "Confusion Matrix on train set:\n",
      " [[4189 1275  272]\n",
      " [1115 8541  967]\n",
      " [  32  754 2855]]\n",
      "Confusion Matrix on valid set:\n",
      " [[1975 1022  213]\n",
      " [ 737 4873  871]\n",
      " [  38  759 1512]]\n"
     ]
    }
   ],
   "source": [
    "print_score(model, X_small, y_small, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5c870839c1aee61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:30:43.041092Z",
     "start_time": "2024-12-03T08:30:43.036853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tree_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f270e1dfc34eac06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:32:24.085578Z",
     "start_time": "2024-12-03T08:30:43.041092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec281e90adaa444d92589c970d1eb12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x303a9a9d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the full list of hyperparameters at \n",
    "# https://catboost.ai/docs/concepts/python-reference_catboostregressor.html#python-reference_catboostregressor\n",
    "# and their explanation at\n",
    "# https://catboost.ai/docs/concepts/python-reference_parameters-list.html#python-reference_parameters-list\n",
    "model = CatBoostClassifier(\n",
    "    n_estimators=5000,  # iterations, n_estimators, num_boost_round, num_trees\n",
    "    random_seed=42,\n",
    "    learning_rate = 0.005, # learning_rate, eta,\n",
    "    loss_function='MultiClass',  \n",
    "    custom_metric=['AUC', 'Accuracy'],  \n",
    "    logging_level='Silent',  \n",
    "    class_weights=None,  \n",
    "    thread_count=-1 \n",
    ")\n",
    "model.fit(X_train, y_train, eval_set = (X_valid, y_valid), plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47366fcc0d8fe239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:32:24.497725Z",
     "start_time": "2024-12-03T08:32:24.085578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.7543\n",
      "Accuracy on valid set: 0.7248\n",
      "Classification Report on train set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73     24275\n",
      "           1       0.79      0.79      0.79     45022\n",
      "           2       0.65      0.74      0.69     15399\n",
      "\n",
      "    accuracy                           0.75     84696\n",
      "   macro avg       0.74      0.74      0.74     84696\n",
      "weighted avg       0.76      0.75      0.75     84696\n",
      "\n",
      "Classification Report on valid set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.64      0.68      3210\n",
      "           1       0.75      0.78      0.77      6481\n",
      "           2       0.63      0.70      0.67      2309\n",
      "\n",
      "    accuracy                           0.72     12000\n",
      "   macro avg       0.71      0.71      0.70     12000\n",
      "weighted avg       0.73      0.72      0.72     12000\n",
      "\n",
      "Confusion Matrix on train set:\n",
      " [[16972  5866  1437]\n",
      " [ 4886 35463  4673]\n",
      " [  280  3669 11450]]\n",
      "Confusion Matrix on valid set:\n",
      " [[2039 1015  156]\n",
      " [ 666 5034  781]\n",
      " [  64  621 1624]]\n"
     ]
    }
   ],
   "source": [
    "print_score(model, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "452a059c805b3b1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:32:43.827326Z",
     "start_time": "2024-12-03T08:32:24.497725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdbc2f9e88224ff9836ab82ea57bebd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n"
     ]
    }
   ],
   "source": [
    "valid_pool = Pool(X_valid, y_valid)\n",
    "auc_scores = model.eval_metrics(valid_pool, metrics='AUC', plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532be67d69a600e4",
   "metadata": {},
   "source": [
    "We want to draw a _cross-validated_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f91ff91cdb87d9dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:41:10.618680Z",
     "start_time": "2024-12-03T08:41:10.615112Z"
    }
   },
   "outputs": [],
   "source": [
    "# cv_dataset = Pool(data=X_small, label=y_small)\n",
    "# \n",
    "# params = {\n",
    "#     \"n_estimators\": 500, \n",
    "#     \"loss_function\": \"MultiClass\",\n",
    "#     \"verbose\": False,\n",
    "# }\n",
    "# \n",
    "# scores = catboost.cv(\n",
    "#     cv_dataset,\n",
    "#     params,\n",
    "#     fold_count = 5, \n",
    "#     plot = \"True\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de04d5f456ca66f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:41:18.499562Z",
     "start_time": "2024-12-03T08:41:13.794346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56dec4e68e5943028459f81b52b238d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x303c90550>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "    n_estimators = 300, # iterations, n_estimators, num_boost_round, num_trees\n",
    "    random_seed = 42,\n",
    "    loss_function = 'MultiClass',\n",
    "    #allow_writing_files = False,\n",
    "    logging_level = 'Silent',\n",
    ")\n",
    "\n",
    "model.fit(X_small, y_small, plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "789d0188516b7384",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:41:18.658020Z",
     "start_time": "2024-12-03T08:41:18.597646Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.8825\n",
      "Accuracy on valid set: 0.6836\n",
      "Classification Report on train set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      5736\n",
      "           1       0.90      0.88      0.89     10623\n",
      "           2       0.87      0.89      0.88      3641\n",
      "\n",
      "    accuracy                           0.88     20000\n",
      "   macro avg       0.88      0.89      0.88     20000\n",
      "weighted avg       0.88      0.88      0.88     20000\n",
      "\n",
      "Classification Report on valid set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.60      0.64      3210\n",
      "           1       0.72      0.75      0.73      6481\n",
      "           2       0.58      0.60      0.59      2309\n",
      "\n",
      "    accuracy                           0.68     12000\n",
      "   macro avg       0.66      0.65      0.66     12000\n",
      "weighted avg       0.68      0.68      0.68     12000\n",
      "\n",
      "Confusion Matrix on train set:\n",
      " [[5118  594   24]\n",
      " [ 847 9299  477]\n",
      " [   8  399 3234]]\n",
      "Confusion Matrix on valid set:\n",
      " [[1937 1093  180]\n",
      " [ 783 4872  826]\n",
      " [  77  838 1394]]\n"
     ]
    }
   ],
   "source": [
    "print_score(model, X_small, y_small, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a92ab735a6d22c",
   "metadata": {},
   "source": [
    "### $\\bullet$ Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6efaf0c88652fb18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:41:20.989721Z",
     "start_time": "2024-12-03T08:41:20.986048Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    n_estimators = 300, # iterations, n_estimators, num_boost_round, num_trees\n",
    "    random_seed = 42,\n",
    "    loss_function = 'MultiClass',\n",
    "    #allow_writing_files = False,\n",
    "    logging_level = 'Silent',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0b22fda5311c717",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:41:38.770701Z",
     "start_time": "2024-12-03T08:41:38.766698Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'min_data_in_leaf': [2, 10, 50],  # equivalent of scikit-learn's 'min_samples_leaf'\n",
    "     'colsample_bylevel': [0.5, 0.75], # equivalent of scikit-learn's max_features\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19a88225f512a57d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:42:55.902465Z",
     "start_time": "2024-12-03T08:41:38.894662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] END ..........colsample_bylevel=0.5, min_data_in_leaf=2; total time=   1.3s\n",
      "[CV] END ..........colsample_bylevel=0.5, min_data_in_leaf=2; total time=   1.6s\n",
      "[CV] END ..........colsample_bylevel=0.5, min_data_in_leaf=2; total time=   1.8s\n",
      "[CV] END ..........colsample_bylevel=0.5, min_data_in_leaf=2; total time=   2.1s\n",
      "[CV] END ..........colsample_bylevel=0.5, min_data_in_leaf=2; total time=   1.8s\n",
      "[CV] END .........colsample_bylevel=0.5, min_data_in_leaf=10; total time=   1.8s\n",
      "[CV] END .........colsample_bylevel=0.5, min_data_in_leaf=10; total time=   1.7s\n",
      "[CV] END .........colsample_bylevel=0.5, min_data_in_leaf=10; total time=   1.7s\n",
      "[CV] END .........colsample_bylevel=0.5, min_data_in_leaf=10; total time=   1.7s\n",
      "[CV] END .........colsample_bylevel=0.5, min_data_in_leaf=10; total time=   1.7s\n",
      "[CV] END .........colsample_bylevel=0.5, min_data_in_leaf=50; total time=   1.7s\n",
      "[CV] END .........colsample_bylevel=0.5, min_data_in_leaf=50; total time=   1.7s\n",
      "[CV] END .........colsample_bylevel=0.5, min_data_in_leaf=50; total time=   1.7s\n",
      "[CV] END .........colsample_bylevel=0.5, min_data_in_leaf=50; total time=   1.7s\n",
      "[CV] END .........colsample_bylevel=0.5, min_data_in_leaf=50; total time=   1.7s\n",
      "[CV] END .........colsample_bylevel=0.75, min_data_in_leaf=2; total time=   1.9s\n",
      "[CV] END .........colsample_bylevel=0.75, min_data_in_leaf=2; total time=   1.9s\n",
      "[CV] END .........colsample_bylevel=0.75, min_data_in_leaf=2; total time=   1.9s\n",
      "[CV] END .........colsample_bylevel=0.75, min_data_in_leaf=2; total time=   1.9s\n",
      "[CV] END .........colsample_bylevel=0.75, min_data_in_leaf=2; total time=   1.9s\n",
      "[CV] END ........colsample_bylevel=0.75, min_data_in_leaf=10; total time=   1.9s\n",
      "[CV] END ........colsample_bylevel=0.75, min_data_in_leaf=10; total time=   1.9s\n",
      "[CV] END ........colsample_bylevel=0.75, min_data_in_leaf=10; total time=   1.9s\n",
      "[CV] END ........colsample_bylevel=0.75, min_data_in_leaf=10; total time=   1.9s\n",
      "[CV] END ........colsample_bylevel=0.75, min_data_in_leaf=10; total time=   1.9s\n",
      "[CV] END ........colsample_bylevel=0.75, min_data_in_leaf=50; total time=   1.9s\n",
      "[CV] END ........colsample_bylevel=0.75, min_data_in_leaf=50; total time=   2.0s\n",
      "[CV] END ........colsample_bylevel=0.75, min_data_in_leaf=50; total time=   1.9s\n",
      "[CV] END ........colsample_bylevel=0.75, min_data_in_leaf=50; total time=   1.9s\n",
      "[CV] END ........colsample_bylevel=0.75, min_data_in_leaf=50; total time=   1.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=&lt;catboost.core.CatBoostClassifier object at 0x303aebd10&gt;,\n",
       "             param_grid=[{&#x27;colsample_bylevel&#x27;: [0.5, 0.75],\n",
       "                          &#x27;min_data_in_leaf&#x27;: [2, 10, 50]}],\n",
       "             return_train_score=True, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=&lt;catboost.core.CatBoostClassifier object at 0x303aebd10&gt;,\n",
       "             param_grid=[{&#x27;colsample_bylevel&#x27;: [0.5, 0.75],\n",
       "                          &#x27;min_data_in_leaf&#x27;: [2, 10, 50]}],\n",
       "             return_train_score=True, verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: CatBoostClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x304098a90&gt;</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">CatBoostClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>&lt;catboost.core.CatBoostClassifier object at 0x304098a90&gt;</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=<catboost.core.CatBoostClassifier object at 0x303aebd10>,\n",
       "             param_grid=[{'colsample_bylevel': [0.5, 0.75],\n",
       "                          'min_data_in_leaf': [2, 10, 50]}],\n",
       "             return_train_score=True, verbose=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(\n",
    "    estimator = model, \n",
    "    param_grid = param_grid, \n",
    "    scoring = None, # uses estimator's default score method\n",
    "    refit = True, # keep a fitted version of the overall best model\n",
    "    cv = 5, \n",
    "    return_train_score = True,\n",
    "    verbose = 2\n",
    ")\n",
    "\n",
    "grid.fit(X_small, y_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7943c7fc1efd91b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:42:55.906735Z",
     "start_time": "2024-12-03T08:42:55.903462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x304098a90>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd2d2d714ea69a0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:43:01.244635Z",
     "start_time": "2024-12-03T08:43:01.240904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf: 2\n"
     ]
    }
   ],
   "source": [
    "params = best_model.get_all_params()\n",
    "\n",
    "print('min_data_in_leaf:', params['min_data_in_leaf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3a4f638073e73dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:43:02.674209Z",
     "start_time": "2024-12-03T08:43:02.619254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.8794\n",
      "Accuracy on valid set: 0.6923\n",
      "Classification Report on train set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      5736\n",
      "           1       0.90      0.87      0.89     10623\n",
      "           2       0.86      0.88      0.87      3641\n",
      "\n",
      "    accuracy                           0.88     20000\n",
      "   macro avg       0.87      0.88      0.88     20000\n",
      "weighted avg       0.88      0.88      0.88     20000\n",
      "\n",
      "Classification Report on valid set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.60      0.65      3210\n",
      "           1       0.72      0.77      0.74      6481\n",
      "           2       0.60      0.60      0.60      2309\n",
      "\n",
      "    accuracy                           0.69     12000\n",
      "   macro avg       0.67      0.66      0.66     12000\n",
      "weighted avg       0.69      0.69      0.69     12000\n",
      "\n",
      "Confusion Matrix on train set:\n",
      " [[5101  600   35]\n",
      " [ 840 9281  502]\n",
      " [   9  425 3207]]\n",
      "Confusion Matrix on valid set:\n",
      " [[1942 1083  185]\n",
      " [ 752 4975  754]\n",
      " [  71  847 1391]]\n"
     ]
    }
   ],
   "source": [
    "print_score(best_model, X_small, y_small, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65b87bdf7dc3b315",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:43:17.378726Z",
     "start_time": "2024-12-03T08:43:03.432770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79625 0.8015  0.7835  0.79425 0.79125]\n",
      "r2 is 0.793 with a standard deviation of 0.006\n"
     ]
    }
   ],
   "source": [
    "# randomized splitting strategy\n",
    "cv = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "scores = cross_val_score(best_model, X_small, y_small, cv = cv)\n",
    "\n",
    "print(scores)\n",
    "print(\"r2 is {:.3f} with a standard deviation of {:.3f}\".format(scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faca38039dc7a9ee",
   "metadata": {},
   "source": [
    "### $\\bullet$ Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7aef11717c950ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:43:18.957702Z",
     "start_time": "2024-12-03T08:43:17.379722Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(\n",
    "    n_estimators = 300, # n_estimators, num_boost_round, num_trees\n",
    "    random_seed = 42,\n",
    "    loss_function = 'MultiClass',\n",
    "    #allow_writing_files = False,\n",
    "    logging_level = 'Silent',\n",
    ")\n",
    "\n",
    "model = model.fit(X_small, y_small, plot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6271df4edb9574a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:43:19.143411Z",
     "start_time": "2024-12-03T08:43:18.957702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outstanding_debt: 11.722299411120627\n",
      "credit_mix: 8.284554691919789\n",
      "interest_rate: 7.593023475819719\n",
      "delay_from_due_date: 6.924514640725791\n",
      "age: 6.158017051592623\n",
      "total_emi_per_month: 6.042167809183885\n",
      "month: 5.674548927232129\n",
      "changed_credit_limit: 5.540166636836345\n",
      "credit_history_age: 5.4827318231927995\n",
      "num_credit_card: 4.77108403982993\n",
      "occupation: 4.216142960753792\n",
      "num_of_delayed_payment: 3.9438391536554773\n",
      "monthly_inhand_salary: 3.7758045484334195\n",
      "num_bank_accounts: 3.7364115795424806\n",
      "num_credit_inquiries: 3.5191828829508913\n",
      "annual_income: 2.9781041015923\n",
      "num_of_loan: 2.5089749217750157\n",
      "monthly_balance: 1.928166015078249\n",
      "payment_behaviour: 1.7525314544470407\n",
      "amount_invested_monthly: 1.6868632666251215\n",
      "credit_utilization_ratio: 1.4098402830807186\n",
      "payment_of_min_amount: 0.35103032461185496\n"
     ]
    }
   ],
   "source": [
    "train_pool = Pool(X_train, y_train)\n",
    "\n",
    "feature_importances = model.get_feature_importance(train_pool)\n",
    "feature_names = X_train.columns\n",
    "for score, name in sorted(zip(feature_importances, feature_names), reverse = True):\n",
    "    print('{}: {}'.format(name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea627e7f9aa9f7a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:43:19.147456Z",
     "start_time": "2024-12-03T08:43:19.144408Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = [n for n, i in zip(feature_names, feature_importances) if i > 0.005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "196e1763acfc83f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:43:19.168180Z",
     "start_time": "2024-12-03T08:43:19.148452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of small training data points: X = (20000, 22), y = (20000,)\n",
      "Number of full training data points: X = (84696, 22), y = (84696,)\n",
      "Number of validation data points: X = (12000, 22), y = (12000,)\n"
     ]
    }
   ],
   "source": [
    "df_keep = df[cols]\n",
    "\n",
    "n_total = len(df_keep)\n",
    "n_valid = 12000\n",
    "n_train = n_total - n_valid\n",
    "n_small = 20000\n",
    "\n",
    "X_train_keep, X_valid_keep = split_vals(df_keep, n_train)\n",
    "y_train, y_valid = split_vals(y, n_train)\n",
    "\n",
    "X_small_keep, _ = split_vals(df_keep, n_small)\n",
    "y_small, _ = split_vals(y, n_small)\n",
    "\n",
    "print('Number of small training data points: X = {}, y = {}'.format(X_small.shape, y_small.shape))\n",
    "print('Number of full training data points: X = {}, y = {}'.format(X_train.shape, y_train.shape))\n",
    "print('Number of validation data points: X = {}, y = {}'.format(X_valid.shape, y_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82755bbce90f379e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:43:20.936070Z",
     "start_time": "2024-12-03T08:43:19.168180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e6618a124b408da64a430f37387aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "    n_estimators = 300, # n_estimators, num_boost_round, num_trees\n",
    "    random_seed = 42,\n",
    "    loss_function = 'MultiClass',\n",
    "    #allow_writing_files = False,\n",
    "    logging_level = 'Silent',\n",
    ")\n",
    "\n",
    "model = model.fit(X_small_keep, y_small, plot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8d2785092d3a5aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T08:43:20.995300Z",
     "start_time": "2024-12-03T08:43:20.937068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.8825\n",
      "Accuracy on valid set: 0.6836\n",
      "Classification Report on train set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      5736\n",
      "           1       0.90      0.88      0.89     10623\n",
      "           2       0.87      0.89      0.88      3641\n",
      "\n",
      "    accuracy                           0.88     20000\n",
      "   macro avg       0.88      0.89      0.88     20000\n",
      "weighted avg       0.88      0.88      0.88     20000\n",
      "\n",
      "Classification Report on valid set:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.60      0.64      3210\n",
      "           1       0.72      0.75      0.73      6481\n",
      "           2       0.58      0.60      0.59      2309\n",
      "\n",
      "    accuracy                           0.68     12000\n",
      "   macro avg       0.66      0.65      0.66     12000\n",
      "weighted avg       0.68      0.68      0.68     12000\n",
      "\n",
      "Confusion Matrix on train set:\n",
      " [[5118  594   24]\n",
      " [ 847 9299  477]\n",
      " [   8  399 3234]]\n",
      "Confusion Matrix on valid set:\n",
      " [[1937 1093  180]\n",
      " [ 783 4872  826]\n",
      " [  77  838 1394]]\n"
     ]
    }
   ],
   "source": [
    "print_score(model, X_small_keep, y_small, X_valid_keep, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "502674e84bdd2723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "import os\n",
    "\n",
    "path_to_model_dir = os.path.join('machine learning',)\n",
    "path_to_model = os.path.join(path_to_model_dir, 'catboost_model.pk')\n",
    "\n",
    "os.makedirs(path_to_model_dir, exist_ok=True)\n",
    "\n",
    "with open(path_to_model, 'wb') as f:\n",
    "    dill.dump(model, f)\n",
    "print(\"Model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a5a5d2-8f00-4c25-8865-60664d92ffd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
